{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff783c3b",
   "metadata": {},
   "source": [
    "# Execução Dirigida — Transfer Learning (Experiência Guiada)\n",
    "\n",
    "### Objetivo\n",
    "Vivenciar, em poucos passos, o uso de **modelos pré-treinados** para perceber o princípio de **Transfer Learning**.\n",
    "\n",
    "- **Máximo de 3 passos operacionais** e **1 decisão** (escolha de caminho).\n",
    "- **Comprovação simples**: uma **saída** do código **+** um **relato breve** (3–5 linhas) no final do notebook.\n",
    "\n",
    "---\n",
    "\n",
    "### Como funciona\n",
    "1. **Passo 1** – Preparar o ambiente e detectar o dispositivo (CPU/CUDA/MPS).  \n",
    "2. **Passo 2 (decisão)** – Escolher **um** caminho:  \n",
    "   - **(A) Visão**: carregar a **ResNet50** pré-treinada.  \n",
    "   - **(B) Texto**: carregar o **GPT-2** e **gerar** uma resposta curta.  \n",
    "3. **Passo 3** – Registrar a **saída** e escrever uma **reflexão** breve.\n",
    "\n",
    "> **Observação**: O download dos pesos pré-treinados requer internet. Se estiver offline, execute assim mesmo para registrar a tentativa (o notebook captura a mensagem de erro)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9895066",
   "metadata": {},
   "source": [
    "## Passo 1 — Preparar o ambiente (dispositivo e versões)\n",
    "Execute a célula para identificar o dispositivo e registrar versões principais (úteis na sua evidência)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e94f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispositivo (CUDA / MPS / CPU)\n",
    "import torch, sys\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                      else \"mps\" if hasattr(torch, \"mps\") and torch.mps.is_available()\n",
    "                      else \"cpu\")\n",
    "print(\"Dispositivo detectado:\", device)\n",
    "\n",
    "# Versões para registro\n",
    "import transformers, datasets\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"Transformers:\", transformers.__version__)\n",
    "print(\"Datasets:\", datasets.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ede8d9",
   "metadata": {},
   "source": [
    "## Passo 2 — Escolha **um** caminho (A **ou** B)\n",
    "\n",
    "### (A) Visão — ResNet50 como **extratora de características**\n",
    "- Carrega a ResNet50 pré-treinada (ImageNet) e mostra a camada final.  \n",
    "- **Saída esperada**: nome do modelo e dimensões da última camada.\n",
    "\n",
    "> Execute **esta** célula se escolher **Visão**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649faa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho (A) Visão — ResNet50\n",
    "try:\n",
    "    import torchvision\n",
    "    from torchvision import models\n",
    "    from torch import nn\n",
    "\n",
    "    # Carregar pesos pré-treinados (requer internet na 1ª vez)\n",
    "    resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "    for p in resnet.parameters():\n",
    "        p.requires_grad = False  # usar como extratora de características\n",
    "\n",
    "    n_features = resnet.fc.in_features\n",
    "    print(\"Modelo:\", type(resnet).__name__)\n",
    "    print(\"Última camada (antes da substituição):\", resnet.fc)\n",
    "    print(\"Dimensões do extrator de features:\", n_features)\n",
    "\n",
    "    # Exemplo: substituir a cabeça para 3 classes (apenas demonstração)\n",
    "    resnet.fc = nn.Linear(n_features, 3)\n",
    "    print(\"Nova cabeça (Linear -> 3 classes):\", resnet.fc)\n",
    "\n",
    "    # (Opcional) Simular um passo de inferência com tensor aleatório (sem imagens reais)\n",
    "    x = torch.randn(2, 3, 224, 224)  # 2 imagens simuladas 224x224 RGB\n",
    "    with torch.no_grad():\n",
    "        y = resnet(x)\n",
    "    print(\"Saída simulada (batch=2, classes=3):\", y.shape)\n",
    "\n",
    "    evidencia_visao = f\"Modelo: ResNet50 | features: {n_features} | saida_simulada: {tuple(y.shape)}\"\n",
    "except Exception as e:\n",
    "    evidencia_visao = f\"[Visão] Falha ao carregar/rodar ResNet50 -> {type(e).__name__}: {e}\"\n",
    "    print(evidencia_visao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde2a72b",
   "metadata": {},
   "source": [
    "### (B) Texto — GPT-2 para **gerar** uma resposta curta\n",
    "- Carrega GPT-2 pré-treinado e gera uma sequência curta.  \n",
    "- **Saída esperada**: texto gerado pelo modelo.\n",
    "\n",
    "> Execute **esta** célula se escolher **Texto**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32791ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho (B) Texto — GPT-2\n",
    "evidencia_texto = None\n",
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "    model_name = \"gpt2\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "    # Seleção de dispositivo para o pipeline (CUDA > MPS > CPU)\n",
    "    if torch.cuda.is_available():\n",
    "        dev = 0\n",
    "    elif hasattr(torch, \"mps\") and torch.mps.is_available():\n",
    "        # algumas versões de transformers não aceitam \"mps\"; fallback para CPU\n",
    "        try:\n",
    "            dev = \"mps\"\n",
    "        except Exception:\n",
    "            dev = -1\n",
    "    else:\n",
    "        dev = -1\n",
    "\n",
    "    pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=dev)\n",
    "\n",
    "    prompt = \"Explique o que é transferência de aprendizado em IA.\"\n",
    "    out = pipe(prompt, max_new_tokens=40, temperature=0.8, top_p=0.9, pad_token_id=tokenizer.eos_token_id)\n",
    "    texto_gerado = out[0][\"generated_text\"]\n",
    "    print(\"Texto gerado:\\n\", texto_gerado)\n",
    "\n",
    "    evidencia_texto = \"Texto gerado OK (GPT-2)\"\n",
    "except Exception as e:\n",
    "    evidencia_texto = f\"[Texto] Falha ao carregar/gerar com GPT-2 -> {type(e).__name__}: {e}\"\n",
    "    print(evidencia_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba796d6",
   "metadata": {},
   "source": [
    "## Passo 3 — Evidência + Relato breve (3–5 linhas)\n",
    "\n",
    "- **Evidência**: uma saída do caminho escolhido (A **ou** B).  \n",
    "- **Relato**: descreva brevemente o que observou sobre o **reaproveitamento** do conhecimento no modelo pré-treinado.\n",
    "\n",
    "> Preencha e rode a célula abaixo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7248210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencha seu relato aqui (entre aspas triplas):\n",
    "relato = \"\"\"\n",
    "No meu teste, observei...\n",
    "\"\"\"\n",
    "\n",
    "# Coleta automática de evidência (pega qualquer uma disponível)\n",
    "evidencia = None\n",
    "for v in [\"evidencia_visao\", \"evidencia_texto\"]:\n",
    "    if v in globals() and globals()[v]:\n",
    "        evidencia = globals()[v]\n",
    "        break\n",
    "\n",
    "print(\"=== EVIDÊNCIA ===\")\n",
    "print(evidencia if evidencia else \"Sem evidência capturada (ok se você estiver offline, descreva no relato).\")\n",
    "print(\"\\n=== RELATO ===\")\n",
    "print(relato.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54c72f5",
   "metadata": {},
   "source": [
    "---\n",
    "### Entrega no Fórum\n",
    "\n",
    "Para concluir esta atividade, poste uma única mensagem no fórum contendo:\n",
    "\n",
    "#### 1.\tEvidência da execução\n",
    "\n",
    "Copie e cole a saída principal obtida no notebook (por exemplo, o texto gerado pelo GPT-2 ou o resumo do modelo carregado da ResNet50).\n",
    "\n",
    "#### 2.\tRelato breve (3–5 linhas)\n",
    "\n",
    "Explique, com suas palavras:\n",
    "- O que o modelo já sabia antes do seu teste?\n",
    "- O que você observou na execução (resultado, comportamento ou erro)?\n",
    "- O que aprendeu sobre o conceito de transferência de aprendizado?\n",
    "\n",
    "**Importante**:\n",
    "\n",
    "Se o ambiente não permitiu baixar ou rodar o modelo (por falta de internet, GPU etc.), registre o ocorrido e descreva o que entendeu sobre o processo.\n",
    "\n",
    "Mesmo sem resultado numérico, isso vale como experiência válida — o essencial é demonstrar compreensão e reflexão sobre o funcionamento do Transfer Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c93396",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
