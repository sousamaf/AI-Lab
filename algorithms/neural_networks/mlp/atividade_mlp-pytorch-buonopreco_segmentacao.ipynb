{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "686b5243",
   "metadata": {},
   "source": [
    "# Segmentação de Clientes com PyTorch (Buonopreço)\n",
    "**Objetivo:** Evoluir da MLP “na mão” para uma **MLP em PyTorch** treinada com `TensorDataset` + `DataLoader` para **classificação multiclasse** (segmentação de clientes).\n",
    "\n",
    "> **Você verá neste notebook:**\n",
    "> - Carregamento e preparo do dataset **Buonopreço**.\n",
    "> - Construção do alvo multiclasse (prioridade: `classe_cliente`; fallback por faixas de gasto).\n",
    "> - Pré-processamento tabular com scikit-learn (numérico + categórico) e conversão para `torch.Tensor`.\n",
    "> - MLP em PyTorch, treino com `DataLoader`, avaliação e curvas.\n",
    "> - Salvamento e carregamento do modelo e do pipeline de pré-processamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4c8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação de dependências principais\n",
    "try:\n",
    "    import torch, torch.nn as nn, torch.optim as optim\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "    TORCH_OK = True\n",
    "    print(\"PyTorch:\", torch.__version__)\n",
    "except Exception as e:\n",
    "    TORCH_OK = False\n",
    "    print(\"PyTorch não disponível neste ambiente. Execute localmente com PyTorch instalado.\")\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "DATA_PATH = \"dataset-buonopreco-registro_de_clientes.csv\"\n",
    "\n",
    "# Hiperparâmetros\n",
    "SEED = 42\n",
    "TEST_SIZE = 0.2\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN = 32\n",
    "EPOCHS = 100\n",
    "LR = 0.03\n",
    "\n",
    "np.random.seed(SEED)\n",
    "if TORCH_OK:\n",
    "    torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1555a8",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Carregar dataset e inspecionar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea0de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Dimensão:\", df.shape)\n",
    "print(\"Colunas:\", list(df.columns)[:20], \"...\")\n",
    "df.head(10)  # exibir preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53e3c5a",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Construir o alvo multiclasse (segmentação)\n",
    "Prioridade: usar **`classe_cliente`** se existir.  \n",
    "Fallback (didático): criar 3 segmentos por **faixas de `gasto_medio`** (baixa/média/alta) usando tercis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a6785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multiclass_target(df):\n",
    "    df_ = df.copy()\n",
    "    # Caso 1: usar 'classe_cliente' diretamente se existir (string/categoria)\n",
    "    if \"classe_cliente\" in df_.columns:\n",
    "        y_raw = df_[\"classe_cliente\"].astype(str).fillna(\"desconhecido\")\n",
    "        X = df_.drop(columns=[\"classe_cliente\"])\n",
    "        note = \"Alvo = 'classe_cliente' (multiclasse).\"\n",
    "        return X, y_raw, note\n",
    "\n",
    "    # Caso 2: fallback por faixas de gasto_medio (3 classes)\n",
    "    if \"gasto_medio\" in df_.columns:\n",
    "        s = pd.to_numeric(df_[\"gasto_medio\"], errors=\"coerce\").fillna(0.0)\n",
    "        # tercis -> rótulos\n",
    "        q = s.quantile([0.33, 0.66]).values\n",
    "        bins = [-np.inf, q[0], q[1], np.inf]\n",
    "        labels = [\"baixo_valor\", \"medio_valor\", \"alto_valor\"]\n",
    "        y_raw = pd.cut(s, bins=bins, labels=labels, include_lowest=True).astype(str)\n",
    "        X = df_.drop(columns=[\"gasto_medio\"])\n",
    "        note = \"Alvo criado por tercis de 'gasto_medio' (baixo/médio/alto).\"\n",
    "        return X, y_raw, note\n",
    "\n",
    "    raise ValueError(\"Não encontrei 'classe_cliente' nem 'gasto_medio' para criar alvo multiclasse.\")\n",
    "\n",
    "X_raw, y_raw, target_note = build_multiclass_target(df)\n",
    "print(\"Target note:\", target_note)\n",
    "print(\"Distribuição de classes:\")\n",
    "print(y_raw.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe8c2ef",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Pré-processamento tabular (scikit-learn)\n",
    "- Remoção de IDs.\n",
    "- Numéricas: imputação (mediana) + padronização.\n",
    "- Categóricas: imputação (mais frequente) + One-Hot (ignorando categorias desconhecidas).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847dd8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover identificadores óbvios\n",
    "id_like = [c for c in X_raw.columns if any(tok in c.lower() for tok in (\"id\", \"codigo\", \"cpf\"))]\n",
    "if id_like:\n",
    "    X_raw = X_raw.drop(columns=id_like)\n",
    "\n",
    "# Separar treino/teste com estratificação\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y_raw)  # 0..K-1\n",
    "class_names = le.classes_.tolist()\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "X_train_df, X_test_df, y_train, y_test = train_test_split(\n",
    "    X_raw, y_enc, test_size=TEST_SIZE, random_state=SEED, stratify=y_enc\n",
    ")\n",
    "\n",
    "# Column selectors\n",
    "numeric_selector = selector(dtype_include=np.number)\n",
    "categorical_selector = selector(dtype_exclude=np.number)\n",
    "\n",
    "numeric_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "categorical_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_pipe, numeric_selector),\n",
    "    (\"cat\", categorical_pipe, categorical_selector)\n",
    "], remainder=\"drop\", verbose_feature_names_out=False)\n",
    "\n",
    "# Fit no treino e transformar treino/teste\n",
    "X_train_np = preprocess.fit_transform(X_train_df).astype(np.float32)\n",
    "X_test_np  = preprocess.transform(X_test_df).astype(np.float32)\n",
    "\n",
    "print(\"Shapes finais:\", X_train_np.shape, X_test_np.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d98ba1d",
   "metadata": {},
   "source": [
    "\n",
    "## 4) TensorDataset + DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_OK:\n",
    "    import torch\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "    X_train_t = torch.from_numpy(X_train_np)\n",
    "    y_train_t = torch.from_numpy(y_train.astype(np.int64))\n",
    "    X_test_t  = torch.from_numpy(X_test_np)\n",
    "    y_test_t  = torch.from_numpy(y_test.astype(np.int64))\n",
    "\n",
    "    train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "    test_ds  = TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    in_dim = X_train_np.shape[1]\n",
    "    out_dim = len(class_names)\n",
    "    in_dim, out_dim\n",
    "else:\n",
    "    print(\"PyTorch indisponível para criar DataLoader.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b36dfe6",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Definir a MLP em PyTorch\n",
    "Arquitetura simples: `Linear → ReLU → Linear` (saída = logits).  \n",
    "Usaremos `CrossEntropyLoss` (já combina LogSoftmax + NLLLoss).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3696ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_OK:\n",
    "    class MLPMulti(nn.Module):\n",
    "        def __init__(self, in_features, hidden, out_features):\n",
    "            super().__init__()\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(in_features, hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, out_features)\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            return self.net(x)  # logits\n",
    "\n",
    "    model = MLPMulti(in_features=in_dim, hidden=HIDDEN, out_features=out_dim)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LR)\n",
    "    print(model)\n",
    "else:\n",
    "    print(\"Modelo não criado (PyTorch indisponível).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f23d539",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Treinamento\n",
    "Fluxo: **forward → loss → backward → step** por época, usando mini-batches do `DataLoader`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e707f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "if TORCH_OK:\n",
    "    def eval_accuracy(loader):\n",
    "        model.eval()\n",
    "        correct = total = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in loader:\n",
    "                logits = model(xb)\n",
    "                preds = logits.argmax(dim=1)\n",
    "                correct += (preds == yb).sum().item()\n",
    "                total += yb.size(0)\n",
    "        return correct / total\n",
    "\n",
    "    history = {\"loss\": [], \"acc_tr\": [], \"acc_te\": []}\n",
    "    t0 = time.time()\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        run_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            run_loss += loss.item() * xb.size(0)\n",
    "        epoch_loss = run_loss / len(train_loader.dataset)\n",
    "        acc_tr = eval_accuracy(train_loader)\n",
    "        acc_te = eval_accuracy(test_loader)\n",
    "        history[\"loss\"].append(epoch_loss)\n",
    "        history[\"acc_tr\"].append(acc_tr)\n",
    "        history[\"acc_te\"].append(acc_te)\n",
    "        if epoch % max(1, EPOCHS//10) == 0 or epoch == 1:\n",
    "            print(f\"Época {epoch:3d}/{EPOCHS} | loss={epoch_loss:.4f} | acc_tr={acc_tr:.3f} | acc_te={acc_te:.3f}\")\n",
    "    t1 = time.time()\n",
    "    print(f\"Treino concluído em {t1 - t0:.2f}s\")\n",
    "else:\n",
    "    print(\"Treino não executado (PyTorch indisponível).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d127bf",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Curvas de treino\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_OK and len(history[\"loss\"])>0:\n",
    "    plt.figure(figsize=(9,4))\n",
    "    plt.plot(history[\"loss\"], label=\"loss (train)\")\n",
    "    plt.xlabel(\"Época\"); plt.ylabel(\"Loss\"); plt.title(\"Curva de perda\"); plt.grid(True); plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(9,4))\n",
    "    plt.plot(history[\"acc_tr\"], label=\"Acurácia treino\")\n",
    "    plt.plot(history[\"acc_te\"], label=\"Acurácia teste\")\n",
    "    plt.xlabel(\"Época\"); plt.ylabel(\"Acurácia\"); plt.title(\"Evolução da acurácia\"); plt.grid(True); plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Sem histórico para plotes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f242d17",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Avaliação final (teste)\n",
    "Relatório de classificação e matriz de confusão.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c83d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_OK:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits_te = model(X_test_t)\n",
    "        y_pred = logits_te.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Acurácia (teste): {acc:.3f}\\n\")\n",
    "    print(\"Relatório de Classificação:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nMatriz de Confusão:\\n\", cm)\n",
    "else:\n",
    "    print(\"Avaliação não executada (PyTorch indisponível).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360d598b",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Salvar modelo e pipeline\n",
    "Salvamos o `state_dict` do modelo, o `LabelEncoder` das classes e o `ColumnTransformer` usado no pré-processamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143dd72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"buonopreco_mlp_multiclasse.pth\"\n",
    "PREP_PATH  = \"buonopreco_preprocess.pkl\"\n",
    "LE_PATH    = \"buonopreco_labelencoder.pkl\"\n",
    "\n",
    "if TORCH_OK:\n",
    "    torch.save({\"state_dict\": model.state_dict(),\n",
    "                \"in_dim\": in_dim,\n",
    "                \"hidden\": HIDDEN,\n",
    "                \"out_dim\": out_dim}, MODEL_PATH)\n",
    "    joblib.dump(preprocess, PREP_PATH)\n",
    "    joblib.dump(le, LE_PATH)\n",
    "    print(\"Arquivos salvos:\")\n",
    "    print(MODEL_PATH)\n",
    "    print(PREP_PATH)\n",
    "    print(LE_PATH)\n",
    "else:\n",
    "    print(\"Artefatos não salvos (PyTorch indisponível).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed81bc96",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Carregar e usar o modelo (exemplo rápido)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d87ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_OK:\n",
    "    ckpt = torch.load(MODEL_PATH, map_location=\"cpu\")\n",
    "    preprocess2 = joblib.load(PREP_PATH)\n",
    "    le2 = joblib.load(LE_PATH)\n",
    "\n",
    "    model2 = MLPMulti(ckpt[\"in_dim\"], ckpt[\"hidden\"], ckpt[\"out_dim\"])\n",
    "    model2.load_state_dict(ckpt[\"state_dict\"])\n",
    "    model2.eval()\n",
    "\n",
    "    # Inferência de exemplo com as primeiras 5 linhas do conjunto de teste original (dataframe)\n",
    "    X_test_df_sample = X_test_df.iloc[:5].copy()\n",
    "    X_test_np2 = preprocess2.transform(X_test_df_sample).astype(np.float32)\n",
    "    with torch.no_grad():\n",
    "        logits = model2(torch.from_numpy(X_test_np2))\n",
    "        pred_ids = logits.argmax(dim=1).numpy()\n",
    "        preds = le2.inverse_transform(pred_ids)\n",
    "    print(\"Predições (amostra de 5):\", preds)\n",
    "else:\n",
    "    print(\"Recarregamento/uso não executado (PyTorch indisponível).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb262f87",
   "metadata": {},
   "source": [
    "\n",
    "## 11) Conclusão orientada ao negócio\n",
    "A MLP multiclasse treinada com PyTorch mostrou capacidade de **diferenciar perfis de clientes** a partir de atributos cadastrais e históricos.  \n",
    "Isso habilita ações como: **segmentação de campanhas**, **priorização de atendimento** e **alocação de benefícios** por grupo de valor.  \n",
    "Com o modelo e o pré-processamento salvos, abre-se caminho para **reprodutibilidade**, **compartilhamento** e **implantação** em sistemas internos.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
