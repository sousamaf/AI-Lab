{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36fbd36f",
   "metadata": {},
   "source": [
    "\n",
    "# LSTM — Classificação de Cliente a partir de Sequências de Engajamento\n",
    "\n",
    "**Objetivo:** prever `classe_cliente` (ex.: *Alto Valor Ticket Médio*, *Familiar Mensalista*, etc.)\n",
    "a partir de uma **sequência curta** (T=8 períodos) com variáveis de **engajamento em WhatsApp** e **consumo**.\n",
    "\n",
    "Este notebook lê `dataset-buonopreco-registro_de_clientes.csv` do seu repositório **AI-Lab**\n",
    "ou via **raw GitHub** e gera uma **sequência sintética** por cliente (8 períodos).\n",
    "Em seguida, treina uma **LSTM** para **classificação multiclasse**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e3612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "SEED = 123\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "plt.rcParams.update({\"figure.figsize\": (7,4)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ac18d3",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Leitura do dataset (local ou raw GitHub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a4222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CANDIDATES = [\n",
    "    './AI-Lab/datasets/dataset-buonopreco-registro_de_clientes.csv',\n",
    "    '../AI-Lab/datasets/dataset-buonopreco-registro_de_clientes.csv',\n",
    "    '../../AI-Lab/datasets/dataset-buonopreco-registro_de_clientes.csv',\n",
    "    '../datasets/dataset-buonopreco-registro_de_clientes.csv',\n",
    "    '../../datasets/dataset-buonopreco-registro_de_clientes.csv',\n",
    "    'https://raw.githubusercontent.com/sousamaf/AI-Lab/main/datasets/dataset-buonopreco-registro_de_clientes.csv',\n",
    "    'https://raw.githubusercontent.com/sousamaf/AI-Lab/master/datasets/dataset-buonopreco-registro_de_clientes.csv',\n",
    "]\n",
    "\n",
    "df = None\n",
    "last_err = None\n",
    "for p in CANDIDATES:\n",
    "    try:\n",
    "        df = pd.read_csv(p)\n",
    "        print(\"Carregado de:\", p)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        last_err = e\n",
    "\n",
    "if df is None:\n",
    "    raise RuntimeError(f\"Falha ao carregar. Último erro: {last_err}\")\n",
    "\n",
    "# Tipagem e categorias\n",
    "num_cols = ['idade','frequencia_mensal','gasto_medio','pct_compras_com_desconto',\n",
    "            'whatsapp_envios','whatsapp_respostas','taxa_resposta_whatsapp']\n",
    "for c in num_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "df['categoria_preferida'] = df['categoria_preferida'].astype('category')\n",
    "df['classe_cliente'] = df['classe_cliente'].astype('category')\n",
    "\n",
    "class_names = list(df['classe_cliente'].cat.categories)\n",
    "class_to_idx = {c:i for i,c in enumerate(class_names)}\n",
    "df['classe_idx'] = df['classe_cliente'].map(class_to_idx)\n",
    "\n",
    "cat_names = list(df['categoria_preferida'].cat.categories)\n",
    "cat_to_idx = {c:i for i,c in enumerate(cat_names)}\n",
    "df['categoria_idx'] = df['categoria_preferida'].map(cat_to_idx)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f440e303",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Geração de sequência sintética (T=8) por cliente\n",
    "\n",
    "- Variáveis por passo: `whatsapp_envios`, `whatsapp_respostas`, `pct_compras_com_desconto`, `gasto_medio`.\n",
    "- A dinâmica é calibrada pela **classe** e **categoria** do cliente para induzir padrões distintos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d5892",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "T = 8\n",
    "\n",
    "def gen_sequence(row, T=8):\n",
    "    # Bases por cliente\n",
    "    env = float(row['whatsapp_envios'])\n",
    "    rsp = float(row['whatsapp_respostas'])\n",
    "    pct = float(row['pct_compras_com_desconto'])/100.0\n",
    "    gmd = float(row['gasto_medio'])\n",
    "    rr  = float(row['taxa_resposta_whatsapp'])\n",
    "    cat = int(row['categoria_idx'])\n",
    "    cls = int(row['classe_idx'])\n",
    "\n",
    "    # Calibração por classe (induzir padrões)\n",
    "    # Alto valor: respostas e gasto tendem a ser maiores\n",
    "    if 'Alto Valor' in row['classe_cliente']:\n",
    "        base_env, base_rsp, base_pct, base_g = env+1.0, rsp+0.7, pct*0.9, gmd*1.05\n",
    "    elif 'Familiar' in row['classe_cliente']:\n",
    "        base_env, base_rsp, base_pct, base_g = env, rsp+0.3, pct*1.1, gmd\n",
    "    else:\n",
    "        base_env, base_rsp, base_pct, base_g = env, rsp, pct, gmd\n",
    "\n",
    "    seq = []\n",
    "    e, r, p, g = base_env, base_rsp, base_pct, base_g\n",
    "    for t in range(T):\n",
    "        # leve sazonalidade e ruído\n",
    "        e = max(0.0, 0.6*e + 0.4*base_env + 0.5*np.sin(2*np.pi*t/6) + np.random.normal(0, 0.5))\n",
    "        r = np.clip(0.7*r + 0.3*base_rsp + 0.1*np.sin(2*np.pi*t/5) + np.random.normal(0, 0.2), 0, e+1e-3)\n",
    "        p = np.clip(0.8*p + 0.2*base_pct + np.random.normal(0, 0.02), 0, 1)\n",
    "        g = max(5.0, 0.7*g + 10.0*e + 30.0*(r/(e+1e-3)) - 15.0*p + (cat%3)*3.0 + np.random.normal(0, 8.0))\n",
    "        seq.append([e, r, p*100.0, g])\n",
    "\n",
    "    return np.array(seq, dtype=np.float32), cls\n",
    "\n",
    "X, y = [], []\n",
    "for _, row in df.iterrows():\n",
    "    s, cls = gen_sequence(row, T=T)\n",
    "    X.append(s)\n",
    "    y.append(cls)\n",
    "\n",
    "X = np.stack(X)  # (N, T, 4)\n",
    "y = np.array(y, dtype=np.int64)\n",
    "\n",
    "print(\"X shape:\", X.shape, \" y shape:\", y.shape, \" num classes:\", len(class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a61c91e",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Split treino/val e DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e456119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx = np.arange(len(X))\n",
    "np.random.shuffle(idx)\n",
    "split = int(0.8*len(idx))\n",
    "tr_idx, va_idx = idx[:split], idx[split:]\n",
    "\n",
    "Xtr, ytr = X[tr_idx], y[tr_idx]\n",
    "Xva, yva = X[va_idx], y[va_idx]\n",
    "\n",
    "class SeqClsDS(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)   # (N, T, F)\n",
    "        self.y = torch.from_numpy(y)   # (N,)\n",
    "    def __len__(self): return self.X.shape[0]\n",
    "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "train_dl = DataLoader(SeqClsDS(Xtr, ytr), batch_size=64, shuffle=True)\n",
    "val_dl   = DataLoader(SeqClsDS(Xva, yva), batch_size=128, shuffle=False)\n",
    "Xtr.shape, Xva.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91d02b7",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Modelo LSTM para classificação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fbaad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size=4, hidden=64, layers=1, num_classes=3, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden, num_layers=layers, batch_first=True, dropout=dropout if layers>1 else 0.0)\n",
    "        self.fc = nn.Linear(hidden, num_classes)\n",
    "    def forward(self, x):\n",
    "        out, (h, c) = self.lstm(x)     # (B, T, H)\n",
    "        logits = self.fc(out[:, -1, :])\n",
    "        return logits\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "num_classes = len(class_names)\n",
    "model = LSTMClassifier(input_size=4, hidden=64, layers=1, num_classes=num_classes).to(device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def accuracy(logits, y):\n",
    "    pred = logits.argmax(dim=1)\n",
    "    return (pred == y).float().mean().item()\n",
    "\n",
    "def run_epoch(dl, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    total_loss, total_acc, count = 0.0, 0.0, 0\n",
    "    for xb, yb in dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        with torch.set_grad_enabled(train):\n",
    "            logits = model(xb)\n",
    "            loss = loss_fn(logits, yb)\n",
    "            if train:\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "        total_loss += float(loss.item()) * xb.size(0)\n",
    "        total_acc  += accuracy(logits, yb) * xb.size(0)\n",
    "        count += xb.size(0)\n",
    "    return total_loss/max(1,count), total_acc/max(1,count)\n",
    "\n",
    "tr_hist, va_hist = [], []\n",
    "EPOCHS = 25\n",
    "for ep in range(EPOCHS):\n",
    "    tl, ta = run_epoch(train_dl, True)\n",
    "    vl, va = run_epoch(val_dl, False)\n",
    "    tr_hist.append((tl, ta)); va_hist.append((vl, va))\n",
    "    if (ep+1) % 5 == 0 or ep == 1:\n",
    "        print(f\"ép {ep+1:02d} | loss_t {tl:.3f} acc_t {ta:.3f} | loss_v {vl:.3f} acc_v {va:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ce8a4",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Curvas de treino/validação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab5ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tr_loss = [x[0] for x in tr_hist]; tr_acc = [x[1] for x in tr_hist]\n",
    "va_loss = [x[0] for x in va_hist]; va_acc = [x[1] for x in va_hist]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tr_loss, label='treino')\n",
    "plt.plot(va_loss, label='validação')\n",
    "plt.xlabel('época'); plt.ylabel('loss'); plt.title('Loss'); plt.legend(); plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tr_acc, label='treino')\n",
    "plt.plot(va_acc, label='validação')\n",
    "plt.xlabel('época'); plt.ylabel('acurácia'); plt.title('Acurácia'); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b242a0",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Matriz de confusão (validação)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3dc4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Coletar predições em val\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in val_dl:\n",
    "        logits = model(xb.to(device)).cpu().numpy()\n",
    "        y_hat = np.argmax(logits, axis=1)\n",
    "        y_pred.extend(y_hat.tolist())\n",
    "        y_true.extend(yb.numpy().tolist())\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef06d60",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Observações didáticas\n",
    "- A tarefa mostra **dependência temporal** entre estímulos (envios), **respostas** e consumo (`gasto_medio`).  \n",
    "- A LSTM aprende **padrões de engajamento** característicos de cada classe.  \n",
    "- Para uso real: substitua a simulação por **histórico real** (semanas/meses), normalize variáveis e avalie métricas mais robustas (macro-F1, ROC por classe, etc.).\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
