{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ddff8b4",
   "metadata": {},
   "source": [
    "\n",
    "# LSTM no contexto de clientes do BuonoPreço\n",
    "**Previsão de `gasto_medio` do próximo mês a partir de uma janela temporal curta.**\n",
    "\n",
    "Este notebook:\n",
    "1) Lê o dataset `dataset-buonopreco-registro_de_clientes.csv` do repositório **AI-Lab** (caminho local `AI-Lab/datasets`) ou diretamente do **GitHub (raw URL)**.  \n",
    "2) Cria **séries temporais sintéticas** por cliente (12 meses) a partir dos atributos estáticos do dataset.  \n",
    "3) Constrói janelas deslizantes `T`→`t+1` e treina uma **LSTM** em PyTorch para prever `gasto_medio` no próximo passo.  \n",
    "4) Plota curvas de loss e uma comparação `y verdadeiro` vs `y predito` no conjunto de validação.\n",
    "\n",
    "> **Nota:** o dataset original é estático (um registro por cliente). Para fins didáticos, geramos **trajetórias mensais plausíveis** baseadas nesses perfis, preservando *ordens de grandeza* e relações entre variáveis (frequência, desconto, WhatsApp etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d923676",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Imports e Configurações\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bfd568",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Reprodutibilidade básica\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Matplotlib sem estilos/cor explícita\n",
    "plt.rcParams.update({\"figure.figsize\": (7,4)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b032fe8",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Leitura do dataset\n",
    "\n",
    "Tentamos os seguintes caminhos em ordem:\n",
    "1. **Local** (caso o repositório esteja clonado): `../datasets/dataset-buonopreco-registro_de_clientes.csv` e `../../datasets/...`\n",
    "2. **Raw GitHub**: `https://raw.githubusercontent.com/sousamaf/AI-Lab/main/datasets/...` (ou `master`)\n",
    "\n",
    "> Em **Google Colab**, esta célula funciona diretamente, pois há acesso à internet. Alternativamente, você pode montar o Google Drive ou clonar o repositório.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CANDIDATES = [\n",
    "    './AI-Lab/datasets/dataset-buonopreco-registro_de_clientes.csv',\n",
    "    '../AI-Lab/datasets/dataset-buonopreco-registro_de_clientes.csv',\n",
    "    '../../AI-Lab/datasets/dataset-buonopreco-registro_de_clientes.csv',\n",
    "    '../datasets/dataset-buonopreco-registro_de_clientes.csv',\n",
    "    '../../datasets/dataset-buonopreco-registro_de_clientes.csv',\n",
    "    'https://raw.githubusercontent.com/sousamaf/AI-Lab/main/datasets/dataset-buonopreco-registro_de_clientes.csv',\n",
    "    'https://raw.githubusercontent.com/sousamaf/AI-Lab/master/datasets/dataset-buonopreco-registro_de_clientes.csv',\n",
    "]\n",
    "\n",
    "last_err = None\n",
    "df = None\n",
    "for path in CANDIDATES:\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        print('Carregado de:', path)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        last_err = e\n",
    "\n",
    "if df is None:\n",
    "    raise RuntimeError(f'Não foi possível carregar o dataset. Último erro: {last_err}')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5b9ade",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Preparação e limpeza\n",
    "\n",
    "- Conversão de tipos numéricos\n",
    "- Criação de índices categóricos para `categoria_preferida` e `classe_cliente` (para uso opcional)  \n",
    "- Checagem da coluna `taxa_resposta_whatsapp` (já fornecida no dataset de exemplo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4823efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cols = ['idade','frequencia_mensal','gasto_medio','pct_compras_com_desconto',\n",
    "            'whatsapp_envios','whatsapp_respostas','taxa_resposta_whatsapp']\n",
    "\n",
    "for c in num_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "df['categoria_preferida'] = df['categoria_preferida'].astype('category')\n",
    "df['classe_cliente'] = df['classe_cliente'].astype('category')\n",
    "\n",
    "cat2idx = dict(enumerate(df['categoria_preferida'].cat.categories))\n",
    "cat_map = {v:k for k,v in cat2idx.items()}\n",
    "df['categoria_idx'] = df['categoria_preferida'].map(cat_map)\n",
    "\n",
    "class2idx = dict(enumerate(df['classe_cliente'].cat.categories))\n",
    "class_map = {v:k for k,v in class2idx.items()}\n",
    "df['classe_idx'] = df['classe_cliente'].map(class_map)\n",
    "\n",
    "df[num_cols].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8b58a7",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Geração de **séries temporais sintéticas** por cliente (12 meses)\n",
    "\n",
    "Usamos um **modelo simples** para simular a evolução mensal de variáveis:\n",
    "- `frequencia_mensal_t` segue um **random walk suave** em torno da base do cliente.\n",
    "- `pct_compras_com_desconto_t` e `taxa_resposta_whatsapp_t` oscilam levemente (sazonalidade curta + ruído).\n",
    "- `gasto_medio_t+1` é **autoregressivo** com dependência em `frequencia`, `desconto` e `resposta_whatsapp`.\n",
    "\n",
    "> É um **modelo didático**, não prescritivo. Parâmetros foram escolhidos para manter valores plausíveis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a7a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_customer_series(row, T=12):\n",
    "    base_freq = float(row['frequencia_mensal'])\n",
    "    base_spend = float(row['gasto_medio'])\n",
    "    base_disc = float(row['pct_compras_com_desconto']) / 100.0\n",
    "    base_rr = float(row['taxa_resposta_whatsapp'])  # 0..1\n",
    "    cat_idx = int(row['categoria_idx'])\n",
    "    idade = float(row['idade'])\n",
    "\n",
    "    freq, disc, rr, spend = [], [], [], []\n",
    "    f, d, r, s = base_freq, base_disc, base_rr, base_spend\n",
    "\n",
    "    for t in range(T):\n",
    "        f = 0.8*f + 0.2*base_freq + np.random.normal(0, 0.03)\n",
    "        d = np.clip(0.8*d + 0.2*base_disc + np.random.normal(0, 0.01), 0, 1)\n",
    "        r = np.clip(0.85*r + 0.15*base_rr + 0.05*np.sin(2*np.pi*t/6) + np.random.normal(0, 0.02), 0, 1)\n",
    "        s = (0.65*s + 30.0*f + 80.0*r - 20.0*d + 0.05*idade + (cat_idx % 3)*5.0 + np.random.normal(0, 10.0))\n",
    "        s = max(10.0, s)\n",
    "\n",
    "        freq.append(f)\n",
    "        disc.append(d*100.0)\n",
    "        rr.append(r)\n",
    "        spend.append(s)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'frequencia_mensal': freq,\n",
    "        'pct_compras_com_desconto': disc,\n",
    "        'taxa_resposta_whatsapp': rr,\n",
    "        'gasto_medio': spend,\n",
    "        'categoria_idx': cat_idx,\n",
    "        'idade': idade,\n",
    "        'cliente_id': row['cliente_id']\n",
    "    })\n",
    "\n",
    "all_series = [simulate_customer_series(row, T=12) for _, row in df.iterrows()]\n",
    "ts_df = pd.concat(all_series, axis=0, ignore_index=True)\n",
    "ts_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb96c7e",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Janelas deslizantes e *dataset* PyTorch\n",
    "\n",
    "Definimos janela `WINDOW=6` para prever `gasto_medio` no passo `t+1`.\n",
    "Entradas: `[frequencia, desconto, resposta, idade, categoria_embedding]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d51a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "WINDOW = 6\n",
    "\n",
    "feature_cols_numeric = ['frequencia_mensal','pct_compras_com_desconto','taxa_resposta_whatsapp','idade']\n",
    "cat_col = 'categoria_idx'\n",
    "target_col = 'gasto_medio'\n",
    "\n",
    "num_features = len(feature_cols_numeric)\n",
    "\n",
    "groups = ts_df.groupby('cliente_id')\n",
    "X_num, X_cat, y = [], [], []\n",
    "for cid, g in groups:\n",
    "    g = g.reset_index(drop=True)\n",
    "    for t in range(len(g) - WINDOW):\n",
    "        X_num.append(g.loc[t:t+WINDOW-1, feature_cols_numeric].values.astype('float32'))\n",
    "        X_cat.append(g.loc[t:t+WINDOW-1, cat_col].values.astype('int64'))\n",
    "        y.append(g.loc[t+WINDOW, target_col].astype('float32'))\n",
    "\n",
    "X_num = np.array(X_num)\n",
    "X_cat = np.array(X_cat)\n",
    "y = np.array(y).reshape(-1, 1)\n",
    "\n",
    "N = len(X_num)\n",
    "idx = np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "split = int(0.8*N)\n",
    "train_idx, val_idx = idx[:split], idx[split:]\n",
    "\n",
    "Xn_tr, Xc_tr, y_tr = X_num[train_idx], X_cat[train_idx], y[train_idx]\n",
    "Xn_va, Xc_va, y_va = X_num[val_idx], X_cat[val_idx], y[val_idx]\n",
    "\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, Xn, Xc, y):\n",
    "        self.Xn = torch.from_numpy(Xn)\n",
    "        self.Xc = torch.from_numpy(Xc)\n",
    "        self.y  = torch.from_numpy(y)\n",
    "    def __len__(self): return self.Xn.shape[0]\n",
    "    def __getitem__(self, i):\n",
    "        return self.Xn[i], self.Xc[i], self.y[i]\n",
    "\n",
    "train_ds = SeqDataset(Xn_tr, Xc_tr, y_tr)\n",
    "val_ds   = SeqDataset(Xn_va, Xc_va, y_va)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_dl   = DataLoader(val_ds, batch_size=128, shuffle=False)\n",
    "\n",
    "n_categories = int(df['categoria_idx'].max()) + 1\n",
    "n_categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f3062",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Modelo LSTM (com *embedding* para categoria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffc7c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMBuono(nn.Module):\n",
    "    def __init__(self, num_features, n_categories, emb_dim=4, hidden=32, layers=1, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_embeddings=n_categories, embedding_dim=emb_dim)\n",
    "        self.lstm = nn.LSTM(input_size=num_features + emb_dim, hidden_size=hidden, num_layers=layers, dropout=dropout if layers>1 else 0.0, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        emb = self.emb(x_cat)\n",
    "        x = torch.cat([x_num, emb], dim=-1)\n",
    "        out, (h, c) = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "model = LSTMBuono(num_features=num_features, n_categories=n_categories, emb_dim=4, hidden=32).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def run_epoch(dloader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    total, count = 0.0, 0\n",
    "    for xb_num, xb_cat, yb in dloader:\n",
    "        xb_num, xb_cat, yb = xb_num.to(device), xb_cat.to(device), yb.to(device)\n",
    "        with torch.set_grad_enabled(train):\n",
    "            yhat = model(xb_num, xb_cat)\n",
    "            loss = loss_fn(yhat, yb)\n",
    "            if train:\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "        total += float(loss.item()) * xb_num.size(0)\n",
    "        count += xb_num.size(0)\n",
    "    return total / max(1, count)\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "EPOCHS = 25\n",
    "for ep in range(EPOCHS):\n",
    "    tl = run_epoch(train_dl, True)\n",
    "    vl = run_epoch(val_dl, False)\n",
    "    train_losses.append(tl); val_losses.append(vl)\n",
    "    if (ep+1) % 5 == 0 or ep == 0:\n",
    "        print(f\"Época {ep+1:02d} | treino MSE: {tl:.2f} | val MSE: {vl:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e303bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label='treino')\n",
    "plt.plot(val_losses, label='validação')\n",
    "plt.xlabel('época'); plt.ylabel('MSE'); plt.title('Curvas de Loss'); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23edbe10",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Avaliação simples no conjunto de validação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fea6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "truth, pred = [], []\n",
    "with torch.no_grad():\n",
    "    for xb_num, xb_cat, yb in val_dl:\n",
    "        yhat = model(xb_num.to(device), xb_cat.to(device)).cpu().numpy().ravel()\n",
    "        pred.extend(yhat.tolist())\n",
    "        truth.extend(yb.numpy().ravel().tolist())\n",
    "\n",
    "k = min(120, len(truth))\n",
    "plt.figure()\n",
    "plt.plot(truth[:k], label='verdadeiro')\n",
    "plt.plot(pred[:k], label='predito')\n",
    "plt.xlabel('amostras'); plt.ylabel('gasto médio'); plt.title('Validação: verdadeiro vs predito'); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209db46d",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Como usar no **Google Colab**\n",
    "\n",
    "- Opção A *(recomendada)*: mantenha a estrutura do repositório e **leia via raw GitHub** (já implementado no loader).  \n",
    "- Opção B: **clonar o repositório**:\n",
    "```bash\n",
    "!git clone https://github.com/sousamaf/AI-Lab.git\n",
    "%cd AI-Lab/algorithms/neural_networks/lstm\n",
    "```\n",
    "- Opção C: **montar o Google Drive** e apontar `CANDIDATES` para o caminho no Drive.\n",
    "\n",
    "Este notebook foi construído para funcionar mesmo fora do repositório, desde que o **raw GitHub** esteja acessível.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e611395",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
