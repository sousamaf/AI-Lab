{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1730ed6",
   "metadata": {},
   "source": [
    "\n",
    "# Como começar com Deep Learning em PyTorch\n",
    "\n",
    "Este notebook mostra os conceitos fundamentais de **Deep Learning** usando o PyTorch.  \n",
    "Nosso foco será comparar uma **rede rasa** com uma **rede profunda**, destacando a diferença de representação.\n",
    "\n",
    "> Dica: execute cada célula em sequência. Ao final, compare as métricas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad392717",
   "metadata": {},
   "source": [
    "## 1) Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac7ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8510ed9",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Preparando um dataset simples\n",
    "\n",
    "Vamos criar um dataset artificial de classificação binária.  \n",
    "Ele é pequeno e didático, adequado para comparar arquiteturas rasas e profundas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c320337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset sintético\n",
    "X, y = make_classification(\n",
    "    n_samples=2000, n_features=20, n_informative=10, n_classes=2, random_state=SEED\n",
    ")\n",
    "\n",
    "# Padronização\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Treino/validação\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "# Tensores\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "X_val   = torch.tensor(X_val,   dtype=torch.float32).to(device)\n",
    "y_val   = torch.tensor(y_val,   dtype=torch.long).to(device)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d598c3f8",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Definindo modelos\n",
    "\n",
    "### 3.1 Rede rasa (1 camada oculta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eb7cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowMLP(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_in, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_out)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "shallow_model = ShallowMLP(20, 16, 2).to(device)\n",
    "shallow_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b20379",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2 Rede profunda (3 camadas ocultas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepMLP(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_in, n_hidden), nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_out)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "deep_model = DeepMLP(20, 64, 2).to(device)\n",
    "deep_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a55833",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Função de treino\n",
    "\n",
    "O ciclo de treino segue três passos: **forward**, **cálculo da loss** e **backward + otimização**.\n",
    "A métrica usada aqui será **acurácia de validação**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed972658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=20, lr=1e-3):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Treino\n",
    "        model.train()\n",
    "        y_pred = model(X_train)\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validação\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(X_val)\n",
    "            val_loss = loss_fn(val_pred, y_val).item()\n",
    "            val_acc = (val_pred.argmax(1) == y_val).float().mean().item()\n",
    "\n",
    "        history[\"train_loss\"].append(loss.item())\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(f\"Época {epoch+1:02d} | \"\n",
    "              f\"Loss treino: {loss.item():.4f} | \"\n",
    "              f\"Loss val: {val_loss:.4f} | \"\n",
    "              f\"Acurácia val: {val_acc:.4f}\")\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85404227",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Comparando desempenho\n",
    "\n",
    "### 5.1 Treinando rede rasa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76203232",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_shallow = train_model(shallow_model, X_train, y_train, X_val, y_val, epochs=20, lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ea91c",
   "metadata": {},
   "source": [
    "\n",
    "### 5.2 Treinando rede profunda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db98783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_deep = train_model(deep_model, X_train, y_train, X_val, y_val, epochs=20, lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9043750b",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Conclusão\n",
    "\n",
    "- A **rede rasa** consegue aprender parte dos padrões, mas tem **limitação de representação**.  \n",
    "- A **rede profunda** tende a obter melhor desempenho, pois representa relações mais complexas.  \n",
    "- Redes profundas exigem mais **dados**, **cálculo** e **regularização** para evitar overfitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
