{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0351e10a",
   "metadata": {},
   "source": [
    "\n",
    "# CNN Didática (PyTorch) — Classificação **CIFAR-10** (32×32 RGB)\n",
    "\n",
    "Este notebook implementa uma **CNN** em **PyTorch** para classificar o **CIFAR-10** (10 classes, imagens 32×32 coloridas).\n",
    "O foco é **didático**: entender o pipeline **dados → rede → treino → avaliação** e visualizar **filtros** e **feature maps**.\n",
    "\n",
    "> Obs.: o download do CIFAR-10 ocorre automaticamente (requer internet na primeira execução).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3300267",
   "metadata": {},
   "source": [
    "## 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e7e2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a80dffa",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Dados — CIFAR-10 (download via `torchvision.datasets`)\n",
    "\n",
    "- Imagens **RGB 32×32**.  \n",
    "- Normalização com médias e desvios-padrão **CIFAR-10**.  \n",
    "- *Augmentation* opcional para treino (rotação e flips leves).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d220fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas padrão do CIFAR-10\n",
    "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "CIFAR10_STD  = (0.2470, 0.2435, 0.2616)\n",
    "\n",
    "train_tfms = T.Compose([\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(CIFAR10_MEAN, CIFAR10_STD)\n",
    "])\n",
    "\n",
    "test_tfms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(CIFAR10_MEAN, CIFAR10_STD)\n",
    "])\n",
    "\n",
    "# Baixa/carrega datasets\n",
    "train_set = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=train_tfms)\n",
    "test_set  = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=test_tfms)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_set,  batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "CLASSES = train_set.classes\n",
    "len(train_set), len(test_set), CLASSES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a43c0",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Amostras do dataset (visualização)\n",
    "\n",
    "Mostramos algumas imagens de treino (desnormalizadas apenas para visualização).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6605e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize(img_tensor):\n",
    "    # img_tensor: (3,H,W) tensor normalized\n",
    "    mean = torch.tensor(CIFAR10_MEAN).view(3,1,1)\n",
    "    std  = torch.tensor(CIFAR10_STD).view(3,1,1)\n",
    "    return img_tensor * std + mean\n",
    "\n",
    "# Pega um batch\n",
    "xb, yb = next(iter(train_loader))\n",
    "xb_vis = xb[:8].cpu()\n",
    "yb_vis = yb[:8].cpu()\n",
    "\n",
    "for i in range(xb_vis.size(0)):\n",
    "    plt.figure(figsize=(3,3))\n",
    "    img = unnormalize(xb_vis[i]).permute(1,2,0).clamp(0,1).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Classe: {CLASSES[yb_vis[i].item()]}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1753ac",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Modelo — CNN simples para 32×32×3\n",
    "\n",
    "Arquitetura didática:\n",
    "\n",
    "- `Conv2d(3→32, k=3, padding=1)` + ReLU  \n",
    "- `Conv2d(32→32, k=3, padding=1)` + ReLU + `MaxPool2d(2)`  → 32×32 → 16×16  \n",
    "- `Conv2d(32→64, k=3, padding=1)` + ReLU  \n",
    "- `Conv2d(64→64, k=3, padding=1)` + ReLU + `MaxPool2d(2)`  → 16×16 → 8×8  \n",
    "- `Flatten` → `Linear(64×8×8 → 256)` → ReLU → `Linear(256→10)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d7172",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 32->16\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 16->8\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*8*8, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = CifarCNN().to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfc8c85",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Treino\n",
    "\n",
    "Usaremos **CrossEntropyLoss** e **Adam**. Reportamos **loss** de treino por época e **acurácia** no conjunto de teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20909210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, epochs=10, lr=1e-3):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    history = {\"train_loss\": [], \"test_acc\": []}\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running += loss.item() * xb.size(0)\n",
    "\n",
    "        epoch_loss = running / len(train_loader.dataset)\n",
    "\n",
    "        # Avaliação\n",
    "        model.eval()\n",
    "        all_preds, all_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in test_loader:\n",
    "                xb = xb.to(device, non_blocking=True)\n",
    "                logits = model(xb)\n",
    "                preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "                all_preds.append(preds)\n",
    "                all_true.append(yb.numpy())\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_true  = np.concatenate(all_true)\n",
    "        acc = accuracy_score(all_true, all_preds)\n",
    "\n",
    "        history[\"train_loss\"].append(epoch_loss)\n",
    "        history[\"test_acc\"].append(acc)\n",
    "        print(f\"Época {epoch:02d} | Loss treino: {epoch_loss:.4f} | Acurácia teste: {acc:.4f}\")\n",
    "    return history\n",
    "\n",
    "hist = train(model, train_loader, test_loader, epochs=10, lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a5d04",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Curvas (Loss de treino e Acurácia de teste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9540b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(hist[\"train_loss\"])\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Loss de treino\")\n",
    "plt.title(\"Curva de Loss (treino)\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(hist[\"test_acc\"])\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Acurácia (teste)\")\n",
    "plt.title(\"Curva de Acurácia (teste)\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c70236",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Avaliação final — Matriz de confusão e relatório\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d08f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds, all_true = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        logits = model(xb)\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_true.append(yb.numpy())\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_true  = np.concatenate(all_true)\n",
    "\n",
    "acc = accuracy_score(all_true, all_preds)\n",
    "cm  = confusion_matrix(all_true, all_preds)\n",
    "print(f\"Acurácia (teste): {acc:.4f}\")\n",
    "print(\"Matriz de confusão:\\n\", cm)\n",
    "print(\"\\nClassification report:\\n\", classification_report(all_true, all_preds, target_names=CLASSES))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbe176c",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Visualizando filtros aprendidos (1ª camada conv — 3×3×3)\n",
    "\n",
    "Mostramos os **filtros (kernels)** aprendidos na primeira camada (`Conv2d(3→32)`).\n",
    "Para visualizar, desnormalizamos linearmente cada filtro para [0,1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb42f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv1_w = model.features[0].weight.cpu().numpy()  # (32,3,3,3)\n",
    "\n",
    "def minmax01(a):\n",
    "    a_min, a_max = a.min(), a.max()\n",
    "    if a_max - a_min < 1e-12:\n",
    "        return np.zeros_like(a)\n",
    "    return (a - a_min) / (a_max - a_min)\n",
    "\n",
    "for i in range(conv1_w.shape[0]):\n",
    "    w = conv1_w[i]  # (3,3,3)\n",
    "    w_img = np.transpose(w, (1,2,0))  # (3,3,3) -> HWC\n",
    "    w_img = minmax01(w_img)\n",
    "    plt.figure(figsize=(2.5,2.5))\n",
    "    plt.imshow(w_img)\n",
    "    plt.title(f\"Filtro conv1 #{i}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea3dc8",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Visualizando um feature map (após 1ª conv + ReLU)\n",
    "\n",
    "Selecionamos uma imagem do **teste**, passamos pela **primeira conv + ReLU** e visualizamos um canal do **mapa de ativação**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a28d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pega uma amostra do teste (desserialize sem augmentation)\n",
    "xb, yb = next(iter(test_loader))\n",
    "sample = xb[0:1].to(device)  # (1,3,32,32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv1 = model.features[0]\n",
    "    relu  = model.features[1]\n",
    "    fmap  = relu(conv1(sample))  # (1,32,32,32)\n",
    "\n",
    "fmap_np = fmap[0].cpu().numpy()  # (32,32,32)\n",
    "\n",
    "# Mostrar imagem original (desnormalizada)\n",
    "def unnormalize(img_tensor):\n",
    "    mean = torch.tensor(CIFAR10_MEAN).view(3,1,1).to(img_tensor.device)\n",
    "    std  = torch.tensor(CIFAR10_STD ).view(3,1,1).to(img_tensor.device)\n",
    "    return img_tensor * std + mean\n",
    "\n",
    "orig = unnormalize(sample[0]).cpu().permute(1,2,0).clamp(0,1).numpy()\n",
    "\n",
    "plt.figure(figsize=(3.5,3.5))\n",
    "plt.imshow(orig)\n",
    "plt.title(f\"Original (classe real: {CLASSES[yb[0].item()]})\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(3.5,3.5))\n",
    "plt.imshow(fmap_np[0], cmap=\"viridis\")\n",
    "plt.title(\"Feature map (canal 0) pós conv1+ReLU\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7cf33c",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Conclusão\n",
    "\n",
    "- Pipeline completo com **CIFAR-10** (RGB 32×32): carregamento, **CNN**, treino, avaliação, e visualizações.  \n",
    "- Vimos **filtros aprendidos** (3×3×3) e **feature maps** iniciais — conectando prática e teoria.  \n",
    "- Extensões possíveis: **data augmentation** mais forte, **regularização** (L2, dropout), e **arquiteturas mais profundas**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
