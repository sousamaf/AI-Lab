{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "053c80c2",
   "metadata": {},
   "source": [
    "\n",
    "# CNN Didática (PyTorch) — Classificação do Digits (8×8)\n",
    "\n",
    "Este notebook implementa uma **Rede Neural Convolucional (CNN)** em **PyTorch** usando o **dataset Digits** do `scikit-learn` (imagens 8×8, sem necessidade de internet).  \n",
    "O objetivo é mostrar, de forma **autocontida e prática**:\n",
    "\n",
    "- Como preparar os dados (tensores 1×8×8);  \n",
    "- Como definir e treinar uma **CNN simples**;  \n",
    "- Como avaliar (acurácia e **matriz de confusão**);  \n",
    "- Como **visualizar filtros** aprendidos e um **feature map** intermediário.\n",
    "\n",
    "> Se você já viu CNNs com MNIST/CIFAR, aqui a lógica é idêntica — apenas mudamos para o `digits` por ser **offline**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4776258",
   "metadata": {},
   "source": [
    "## 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55421259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be85010c",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Dados — `sklearn.datasets.load_digits()`\n",
    "\n",
    "- Imagens **8×8** em escala de cinza (valores de 0 a 16).  \n",
    "- Convertidas para **float32** e normalizadas para `[0,1]`.  \n",
    "- Reformatadas para o formato **(N, 1, 8, 8)** esperado pela CNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f52f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.images  # shape (N, 8, 8), valores de 0..16\n",
    "y = digits.target  # rótulos de 0..9\n",
    "\n",
    "X = (X / 16.0).astype(np.float32)\n",
    "X = X[:, None, :, :]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_t  = torch.tensor(X_test,  dtype=torch.float32)\n",
    "y_test_t  = torch.tensor(y_test,  dtype=torch.long)\n",
    "\n",
    "train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "test_ds  = TensorDataset(X_test_t,  y_test_t)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False)\n",
    "\n",
    "X_train_t.shape, y_train_t.shape, X_test_t.shape, y_test_t.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273ae35a",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Modelo — CNN simples\n",
    "\n",
    "Arquitetura didática para 8×8:\n",
    "\n",
    "- `Conv2d(1 → 16, kernel=3, padding=1)` + ReLU  \n",
    "- `MaxPool2d(2)` → reduz 8×8 → 4×4  \n",
    "- `Conv2d(16 → 32, kernel=3, padding=1)` + ReLU  \n",
    "- `MaxPool2d(2)` → reduz 4×4 → 2×2  \n",
    "- `Flatten` → `Linear(32×2×2 → 64)` → ReLU → `Linear(64 → 10)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e237007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32*2*2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b758b2",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Treino\n",
    "\n",
    "Usaremos **CrossEntropyLoss** e **Adam**.  \n",
    "O loop reporta `loss` de treino por época e calcula a **acurácia** no conjunto de teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c612927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, epochs=10, lr=1e-3):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    history = {\"train_loss\": [], \"test_acc\": []}\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running += loss.item() * xb.size(0)\n",
    "\n",
    "        epoch_loss = running / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_true = []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in test_loader:\n",
    "                xb = xb.to(device)\n",
    "                logits = model(xb)\n",
    "                preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "                all_preds.append(preds)\n",
    "                all_true.append(yb.numpy())\n",
    "        import numpy as np\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_true  = np.concatenate(all_true)\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        acc = accuracy_score(all_true, all_preds)\n",
    "\n",
    "        history[\"train_loss\"].append(epoch_loss)\n",
    "        history[\"test_acc\"].append(acc)\n",
    "\n",
    "        print(f\"Época {epoch:02d} | Loss treino: {epoch_loss:.4f} | Acurácia teste: {acc:.4f}\")\n",
    "    return history\n",
    "\n",
    "hist = train(model, train_loader, test_loader, epochs=12, lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c498d9cb",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Curvas (Loss de treino e Acurácia de teste)\n",
    "\n",
    "**Uma figura por gráfico** (sem subplots).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6d0b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(hist[\"train_loss\"])\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Loss de treino\")\n",
    "plt.title(\"Curva de Loss (treino)\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(hist[\"test_acc\"])\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Acurácia (teste)\")\n",
    "plt.title(\"Curva de Acurácia (teste)\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55204cf7",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Avaliação final — Matriz de confusão e relatório\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33420caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_true = []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_true.append(yb.numpy())\n",
    "import numpy as np\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_true  = np.concatenate(all_true)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "acc = accuracy_score(all_true, all_preds)\n",
    "cm  = confusion_matrix(all_true, all_preds)\n",
    "print(f\"Acurácia (teste): {acc:.4f}\")\n",
    "print(\"Matriz de confusão:\\n\", cm)\n",
    "print(\"\\nClassification report:\\n\", classification_report(all_true, all_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a83e822",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Visualizando filtros (1ª camada conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc15b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv1_weights = model.features[0].weight.cpu().numpy()\n",
    "\n",
    "print(\"conv1_weights shape:\", conv1_weights.shape)\n",
    "\n",
    "for i in range(conv1_weights.shape[0]):\n",
    "    w = conv1_weights[i, 0, :, :]\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(w, cmap=\"gray\")\n",
    "    plt.title(f\"Filtro conv1 #{i}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b848e3",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Visualizando um feature map (após 1ª conv + ReLU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0097eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "sample_img = X_test_t[idx:idx+1].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv1 = model.features[0]\n",
    "    relu  = model.features[1]\n",
    "    fmap  = relu(conv1(sample_img))\n",
    "\n",
    "fmap_np = fmap[0].cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(sample_img[0,0].cpu(), cmap=\"gray\")\n",
    "plt.title(\"Imagem original (8×8)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(fmap_np[0], cmap=\"gray\")\n",
    "plt.title(\"Feature map (canal 0)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed00a084",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Conclusão\n",
    "\n",
    "- A CNN aprendeu **filtros locais** (3×3) úteis para distinguir dígitos.  \n",
    "- Vimos o ciclo completo: **dados → CNN → treino → avaliação → visualização**.  \n",
    "- A mesma lógica escala para imagens maiores (28×28, 32×32) com arquiteturas um pouco mais profundas.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
